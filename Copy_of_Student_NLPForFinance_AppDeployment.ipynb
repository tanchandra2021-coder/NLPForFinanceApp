{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HyJtAWKsOm3"
      },
      "source": [
        "<font color=\"red\"><h1><b><u>MAKE A COPY OF THIS NOTEBOOK SO YOUR EDITS ARE SAVED</u></b></h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVJ14FlZA6oV"
      },
      "source": [
        "---\n",
        "---\n",
        "# üåç ***NLP For Finance: Deploying Your Model***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToouZV8bDsO-"
      },
      "source": [
        "<center> <img src=\"https://www.johnsnowlabs.com/wp-content/uploads/2023/03/Examining-The-Impact-Of-NLP_1.jpg\" alt=\"drawing\" width=\"800\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YqyjMUo3DHWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb45c019-138a-44bc-a604-5421b13c75ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train and Test Files Loaded as train.csv and test.csv\n"
          ]
        }
      ],
      "source": [
        "#@title **üèó Setup Cell** {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "#@markdown **Run this to import libraries and download data!**\n",
        "\n",
        "\n",
        "# Installing Streamlit & pyngrok\n",
        "!pip install streamlit -q\n",
        "!pip install pyngrok -q\n",
        "!pip install transformers -q\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import streamlit as st\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from keras.utils import pad_sequences\n",
        "import torch\n",
        "\n",
        "!wget -q 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20NLP%2BFinance/finance_test.csv'\n",
        "!wget -q 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20NLP%2BFinance/finance_train.csv'\n",
        "print (\"Train and Test Files Loaded as train.csv and test.csv\")\n",
        "\n",
        "def get_finance_train():\n",
        "  df_train = pd.read_csv(\"finance_train.csv\")\n",
        "  return df_train\n",
        "\n",
        "def get_finance_test():\n",
        "  df_test = pd.read_csv(\"finance_test.csv\")\n",
        "  return df_test\n",
        "\n",
        "def launch_website():\n",
        "  try:\n",
        "    if ngrok.get_tunnels():\n",
        "      ngrok.kill()\n",
        "    tunnel = ngrok.connect()\n",
        "\n",
        "    print(\"Click this link to try your web app:\")\n",
        "    print(tunnel.public_url)\n",
        "\n",
        "    !streamlit run --server.port 80 app.py >/dev/null # Connect to the URL through Port 80 (>/dev/null hides outputs)\n",
        "\n",
        "  except KeyboardInterrupt:\n",
        "    ngrok.kill()\n",
        "\n",
        "def plot_confusion_matrix(y_true,y_predicted):\n",
        "  cm = metrics.confusion_matrix(y_true, y_predicted)\n",
        "  print (\"Plotting the Confusion Matrix\")\n",
        "  labels = [\"Negative\",\"Neutral\",\"Positive\"]\n",
        "  df_cm = pd.DataFrame(cm,index =labels,columns = labels)\n",
        "  fig = plt.figure(figsize=(7,6))\n",
        "  res = sns.heatmap(df_cm, annot=True,cmap='Blues', fmt='g')\n",
        "  plt.yticks([0.5,1.5,2.5], labels,va='center')\n",
        "  plt.title('Confusion Matrix - TestData')\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()\n",
        "  plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7Rz7HxjD2KA"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "You can find a more detailed Table of Contents by clicking on the icon on the left sidebar that looks like this: <img src=\"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%201a%20-%20AI%20Fundamentals/table_of_contents_icon.png\" width=20>.\n",
        "\n",
        "\n",
        ">[üõú Milestone 1: Streamlit](#scrollTo=iqp5tjXRBBHl)\n",
        "\n",
        ">>[1.1. ngrok](#scrollTo=y0lOuFkdCtAd)\n",
        "\n",
        ">>[1.2. Launching An Example Website](#scrollTo=pFMqHmWKCyGR)\n",
        "\n",
        ">[üõ† Milestone 2: Building Our Web App](#scrollTo=lFqyS-fGC6wo)\n",
        "\n",
        ">>[2.1. Starting Our app.py File with Our Model](#scrollTo=L7vPClO8lVdS)\n",
        "\n",
        ">>[2.2. Handling Data Processing](#scrollTo=BQCF3f2RYiMn)\n",
        "\n",
        ">>[2.3. Building Our Web Interface](#scrollTo=VHbaSdywtkaa)\n",
        "\n",
        ">>[(Optional) 2.4. Visualizations](#scrollTo=fetgQOoixpFI)\n",
        "\n",
        ">[üéÅ Wrapping Up](#scrollTo=mACzv6SLdqjm)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqp5tjXRBBHl"
      },
      "source": [
        "---\n",
        "---\n",
        "# üõú **Milestone 1: Streamlit**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzHhonEuBvix"
      },
      "source": [
        "\n",
        "<center>\n",
        "<img src=\"https://images.datacamp.com/image/upload/v1640050215/image27_frqkzv.png\" alt=\"Streamlit\" width=\"250\" height=\"150\">\n",
        "</center>\n",
        "\n",
        "Today, we'll be using [Streamlit](https://docs.streamlit.io)! Unlike traditional web development which often requires an understanding of multiple languages like HTML, CSS, and JavaScript, Streamlit simplifies this process by offering a Python-centric approach. With just a few lines of code, you can quickly build and format a website\n",
        "\n",
        "Take a moment to look through examples of websites built with Streamlit [here](https://streamlit.io/gallery?category=favorites). As a class, choose your favorite and answer the following **questions:**\n",
        "* Who is this application for?\n",
        "* How does the user input data - are these intuitive ways of interacting with the app?\n",
        "* What does the application do with the data?\n",
        "* Evaluate the ease of use and look of the application.\n",
        "\n",
        "Now that we've seen what is possible with Streamlit, let's try to deploy our **NLP for Finance model** to the web!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0lOuFkdCtAd"
      },
      "source": [
        "## **1.1. ngrok**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33Qs8JGovK5C"
      },
      "source": [
        "Before we start deploying our website, we need to set up a few things. First, we need to set up **tunneling.** Tunneling is a technique that allows you to expose your local server to the public internet. This is especially useful for web applications. We'll use <font color=\"#0e86d4\"><b>`pyngrok`</b></font> for this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET-VFG0OAGaz"
      },
      "source": [
        "<font color=SlateGrey><h4><b>\n",
        "Use [these](https://drive.google.com/file/d/12zwuOuKh91VSHIHS-6S4ADF4HLC2wKJq/view?usp=sharing) instructions to create a ngrok account and get your authtoken!\n",
        "</b></h4></font>\n",
        "\n",
        "<font color=DarkGray><h4><b>\n",
        "Paste your authtoken below next to `!ngrok authtoken`!\n",
        "</b></h4></font>\n",
        "\n",
        "Make sure to input your authtoken in quotation marks! For instance:\n",
        "```python\n",
        "!ngrok authtoken \"YOURAUTHTOKEN1920131248302430409\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwGo_p7pq6rG",
        "outputId": "eaa4d5b0-fab7-49fe-f1f3-44198b7ac533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken \"31r9am2PA3poqnxaP7kQ6Vai8B4_hA3rFFphESLCKSbL2g1C\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP79rTQMwB-D"
      },
      "source": [
        "This authentication token will configure Streamlit to push our local site to the web through ngrok!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFMqHmWKCyGR"
      },
      "source": [
        "## **1.2. Launching An Example Website**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDfnOQpFUOPb"
      },
      "source": [
        "To deploy our web app, we will need to have all of the relevant code for the app in a Python file we'll call <font color=\"#0e86d4\"><b>`app.py`</b></font>.\n",
        "\n",
        "In Google Colab, we can write to a new file using the **`%%writefile`** command at the top of the code cell. This basically takes the text in the rest of the code cell and writes it to <font color=\"#0e86d4\"><b>`app.py`</b></font>, overwriting what might already be in that file, or creating a new file if it doesn't already exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9AiVzybVGOz",
        "outputId": "85877273-6edd-4713-c02e-91127d856565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st  # Importing Streamlit, since app.py is the only code our app sees\n",
        "st.text(\"Hello world!\") # st.text() is like print(), except it prints on our website instead!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJB5gX5g4lXQ"
      },
      "source": [
        "You may notice that this doesn't output anything other than the fact that it's written to the <font color=\"#0e86d4\"><b>`app.py`</b></font> file. This is because we've created a file but haven't actually run it yet. You can check out the newly created file by clicking the folder icon üìÅ on the left sidebar.\n",
        "\n",
        "\n",
        "To run our <font color=\"#0e86d4\"><b>`app.py`</b></font> file, we can use our <font color=\"#0e86d4\"><b>`launch_website()`</b></font> function, which takes that code and deploys it to a web app using Streamlit and ngrok.\n",
        "\n",
        "Run the cell below, and click on the link that it generates to visit your website! You can click on the \"Visit Site\" button after opening the link to see your site.\n",
        "\n",
        ">NOTE: Every time you're done looking at the website you're making, be sure to stop the `launch_website()` cell so you can run other code in this notebook! You can do so by clicking the buffering stop button ‚èπ on the cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5BMhLiqvIjT",
        "outputId": "0a061365-8a7f-4fed-8bc7-84c7211b74bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Click this link to try your web app:\n",
            "https://2e55458a1220.ngrok-free.app\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ],
      "source": [
        "launch_website()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hzPortU1qyv"
      },
      "source": [
        "‚úÖ <font color=#00ab41><b>\n",
        "Congratulations, you have your first working site!\n",
        "</b></font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFqyS-fGC6wo"
      },
      "source": [
        "---\n",
        "---\n",
        "# üõ† **Milestone 2: Building Our Web App**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6iytTSFSxcf"
      },
      "source": [
        "Next, let's start building an interface that our users can interact with! One of the ways users can work with our model is by giving them a way to input example tweets or news statements about specific stocks that the model can classify as either positive or negative. To do this, we need to do a few things:\n",
        "\n",
        "1. Load the pre-trained BERT model and tokenizer.\n",
        "2. Set up the Streamlit UI to allow users to input text.\n",
        "3. Process user input using the tokenizer.\n",
        "4. Predict using the model and classify the sentiment.\n",
        "5. Display the results to the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7vPClO8lVdS"
      },
      "source": [
        "## **2.1. Starting Our <font color=\"#0e86d4\"><b>`app.py`</b></font> File with Our Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJcDPiEIwnyF"
      },
      "source": [
        "Let's reload and take a look at the model and data we've built from our project so far. We've re-imported our data from before in the setup cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YLwOY3Yh3gy",
        "outputId": "6c567593-1984-46e5-dfca-1a1e1a169339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Model and tokenizer loaded!\n"
          ]
        }
      ],
      "source": [
        "#@title Run this cell to load your saved model! {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "from google.colab import drive, files\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from IPython.display import Markdown\n",
        "\n",
        "#@markdown If you downloaded the file to your computer instead of Drive, uncheck the box and follow the upload prompt.\n",
        "load_from_Google_Drive = True  # @param {\"type\":\"boolean\"}\n",
        "folder_name = \"NLP_For_Finance_BERT_Model\"\n",
        "\n",
        "if load_from_Google_Drive:\n",
        "  drive.mount('/content/drive')\n",
        "  zip_path = f'/content/drive/My Drive/{folder_name}.zip'\n",
        "else:\n",
        "  display(Markdown(\"\"\"\n",
        "Please upload your model zip file using the **Choose Files** button below!\n",
        "\n",
        "NOTE: If your files aren't uploading correctly, you can also upload files using the file menu:\n",
        "1. üëàüèº Click the folder icon üìÅ on the left sidebar.\n",
        "2. Click the upload button that looks like a page with an up arrow in it (üìÑ‚¨Ü) and upload your file!\n",
        "---\n",
        "\"\"\"))\n",
        "  uploaded = files.upload()\n",
        "  zip_path = list(uploaded.keys())[0]  # Get the uploaded filename\n",
        "\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(folder_name)\n",
        "\n",
        "if load_from_Google_Drive:\n",
        "  drive.flush_and_unmount()\n",
        "\n",
        "print(\"‚úÖ Model and tokenizer loaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1xOJpJllmdy"
      },
      "source": [
        "Below is a code cell with the outline for your app! We'll go through each step in subsequent exercises so that you can fill in each piece.\n",
        "\n",
        "We suggest going into split-screen mode to edit your <font color=\"#0e86d4\"><b>`app.py`</b></font> code. You can do this by:\n",
        "\n",
        "1. Clicking the code cell below\n",
        "2. Clicking the symbol in the top right of the code cell with two squares and an arrow pointing to the top right, like these symbols: ‚ßâ‚Üó\n",
        "\n",
        ">NOTE: Make sure you run the cell again every time you make an edit, which you should be able to do with the play button in the top left of the new window.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDpobdT2ZHAI"
      },
      "source": [
        "We've already handled the first step for you! Remember, this is the only code that your app will see, so we have to include *everything*, even the import of libraries we might've already imported in this notebook.\n",
        "\n",
        "All you'd potentially need to change is the `model_path` variable, if you changed the name of your model file to something other than the default name `\"NLP_For_Finance_BERT_Model.zip\"` from the previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WtHO9T9dwX6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a352a750-b161-4ab6-9164-032c08cbaf6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "# ‚ÜñÔ∏è Run this cell every time you make any changes!\n",
        "\n",
        "############## STEP 1: Import libraries, load BERT model/tokenizer #############\n",
        "\n",
        "# Imports\n",
        "import streamlit as st\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import os\n",
        "\n",
        "@st.cache_resource  # Cache to load model/tokenizer only once per session\n",
        "def load_model_and_tokenizer():\n",
        "\n",
        "    # Local model path (if available)\n",
        "    local_path = \"NLP_For_Finance_BERT_Model\"\n",
        "    # Hugging Face Hub path (replace with your username/repo)\n",
        "    hub_path = \"username/my-finance-bert\"\n",
        "\n",
        "    if os.path.isdir(local_path):\n",
        "        model_path = local_path\n",
        "        st.info(\"Loading model from local folder...\")\n",
        "    else:\n",
        "        model_path = hub_path\n",
        "        st.info(\"Loading model from Hugging Face Hub...\")\n",
        "\n",
        "    # Load model + tokenizer\n",
        "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "\n",
        "    # Set model to evaluation mode, move to GPU if available\n",
        "    model.eval()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    return model, tokenizer, device\n",
        "\n",
        "# Call the function to get cached model, tokenizer, and device\n",
        "model, tokenizer, device = load_model_and_tokenizer()\n",
        "\n",
        "\n",
        "########################### STEP 2: Helper Functions ###########################\n",
        "\n",
        "### Preprocessing Function\n",
        "def prepare_input(text):\n",
        "    # Add special tokens\n",
        "    sentence_with_tokens = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "    # Tokenize sentence\n",
        "    tokenized_text = tokenizer.tokenize(sentence_with_tokens)\n",
        "\n",
        "    # Convert tokens to IDs\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    # Pad the input IDs\n",
        "    input_ids = pad_sequences([input_ids],\n",
        "                              maxlen=128,\n",
        "                              dtype=\"long\",\n",
        "                              truncating=\"post\",\n",
        "                              padding=\"post\")[0]\n",
        "\n",
        "    # Create attention masks\n",
        "    attention_mask = [float(i > 0) for i in input_ids]\n",
        "    return torch.tensor([input_ids]), torch.tensor([attention_mask])\n",
        "\n",
        "\n",
        "### Prediction Function\n",
        "def predict(text):\n",
        "    # Use our processing function on the input text\n",
        "    input_ids, attention_mask = prepare_input(text)\n",
        "\n",
        "    # Pass the processed data to the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids.to(device), token_type_ids=None, attention_mask=attention_mask.to(device))\n",
        "\n",
        "    # Convert the output logits to probabilities and return!\n",
        "    logits = outputs[0]\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=1).cpu().numpy().flatten()\n",
        "    return probabilities\n",
        "\n",
        "\n",
        "########################## STEP 3: Streamlit interface #########################\n",
        "\n",
        "### Interface\n",
        "st.title('Sentiment Analysis with BERT')\n",
        "text = st.text_area(\"Enter the text to analyze below!\")\n",
        "button = st.button(\"Submit\")\n",
        "\n",
        "### Button logic\n",
        "if button:\n",
        "    if text:\n",
        "        # Get Model's Prediction\n",
        "        probabilities = predict(text)\n",
        "\n",
        "        # Pair the labels with the probabilities in a dictionary\n",
        "        labels = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "        # Print out the results on the Streamlit site\n",
        "        st.write(\"### Sentiment Probabilities:\")\n",
        "        for label, prob in zip(labels, probabilities):\n",
        "            st.write(f\"{label}: {prob:.4f}\")\n",
        "\n",
        "        # (Optional) Pie Chart Visualization\n",
        "        fig = px.pie(values=probabilities, names=labels, title=\"Sentiment Distribution\")\n",
        "        st.plotly_chart(fig)\n",
        "\n",
        "    else:\n",
        "        st.error(\"Please enter a text to analyze.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQCF3f2RYiMn"
      },
      "source": [
        "## **2.2. Handling Data Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jYJJud9KxAE"
      },
      "source": [
        "### 2.2.1. Coding Exercise: Adding the Data Processing Helper Function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdD7f92qs0Y1"
      },
      "source": [
        "Next, we need to preprocess our data. In the code cell below, there's a starter template for the function we'll use to process the data, similar to what we did in Notebook 3!\n",
        "\n",
        "Copy the template code below into your <font color=\"#0e86d4\"><b>`app.py`</b></font> file under <font color=\"green\">`### Preprocessing Function`</font> and replace the <font color=\"#0e86d4\"><b>`None`</b></font> values! Don't edit the template code below, so you can start with a fresh template in case you make mistakes.\n",
        "\n",
        "*Hint*: Feel free to reference your code in Notebook 3!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg0AfFf7sx9s"
      },
      "outputs": [],
      "source": [
        "def prepare_input(text):\n",
        "  ### YOUR CODE HERE: Add special tokens on either end of the input `text`\n",
        "  sentence_with_tokens = None\n",
        "  ### END CODE HERE\n",
        "\n",
        "  # Tokenize sentence\n",
        "  tokenized_text = tokenizer.tokenize(sentence_with_tokens)\n",
        "\n",
        "  # Convert tokens to IDs\n",
        "  input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "  # Pad the input IDs\n",
        "  input_ids = pad_sequences([input_ids],\n",
        "                              maxlen=128,\n",
        "                              dtype=\"long\",\n",
        "                              truncating=\"post\",\n",
        "                              padding=\"post\")[0]\n",
        "\n",
        "  ### YOUR CODE HERE: Create attention masks\n",
        "  attention_mask = None\n",
        "  ### END CODE HERE\n",
        "\n",
        "  return torch.tensor([input_ids]), torch.tensor([attention_mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdJe92INYykD"
      },
      "source": [
        "### 2.2.2. Coding Exercise: Adding the Prediction Helper Function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r2nvD07tY8i"
      },
      "source": [
        "Now that our function for formatting our data is set up properly, we can finally pass text into our model for predictions. Since the prediction logic was handled for you in Notebook 3, we've handled the logic again for you below.\n",
        "\n",
        "All you need to do is paste this into your <font color=\"#0e86d4\"><b>`app.py`</b></font> file under <font color=\"green\">`### Prediction Function`</font>! Feel free to read through the code below if you're curious."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs0FZmb-tgsY"
      },
      "outputs": [],
      "source": [
        "def predict(text):\n",
        "  # Use our processing function on the input text\n",
        "  input_ids, attention_mask = prepare_input(text)\n",
        "\n",
        "  # Pass the processed data to the model (torch.no_grad() disables computing of\n",
        "  # gradients, which are only useful when training)\n",
        "  with torch.no_grad():\n",
        "      outputs = model(input_ids.to(device),\n",
        "                      token_type_ids=None,\n",
        "                      attention_mask=attention_mask.to(device))\n",
        "\n",
        "  # Conver the output logits to probabilities and return!\n",
        "  logits = outputs[0]\n",
        "  probabilities = torch.nn.functional.softmax(logits, dim=1).cpu().numpy().flatten()\n",
        "  return probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHbaSdywtkaa"
      },
      "source": [
        "## **2.3. Building Our Web Interface**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLDvHui0K_cS"
      },
      "source": [
        "How will we make our app interactive for users? Let's allow them to input example text, and we'll pass it to our model for classification. The code cell below contains an example of how you can ask the user for text and allow them to submit it.\n",
        "\n",
        "Copy this code under <font color=\"green\">`### Interface`</font> in your <font color=\"#0e86d4\"><b>`app.py`</b></font>, and feel free to make any changes to the title and messages displayed to the user! Make sure you run your <font color=\"#0e86d4\"><b>`app.py`</b></font> cell again to overwrite the file with these changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tlqNPZxuZQP",
        "outputId": "3be18925-1cb7-488c-fa0c-20547b0832eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-08-28 20:18:44.286 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.396 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-08-28 20:18:44.397 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.398 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.399 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.402 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.403 Session state does not function when running a script without `streamlit run`\n",
            "2025-08-28 20:18:44.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.405 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.406 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.407 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.407 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.408 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.409 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.410 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-28 20:18:44.411 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "# Title of webpage\n",
        "st.title('Finance Stock Predictor!!')\n",
        "\n",
        "# Gets text from the user\n",
        "text = st.text_area(\"Enter the text to analyze below!\")\n",
        "\n",
        "# Displays a button; we'll add some logic later for when the button is clicked\n",
        "button = st.button(\"Submit\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJRLL5zguZ9S"
      },
      "source": [
        "Now that we have something that will show up on the website, let's try it out! Remember, *the button won't do anything* since we don't have any code to handle that just yet.\n",
        "\n",
        "Run the cell below to get your app's link, and stop the cell when you're done checking out your site!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEv6gE82ujlB",
        "outputId": "9b6075e9-a59b-4a89-b4c1-67cf7af527e4"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Click this link to try your web app:\n",
            "https://a2242e593bef.ngrok-free.app\n",
            "2025-08-28 20:18:59.719994: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756412339.770274   30779 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756412339.784596   30779 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756412339.824756   30779 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756412339.824813   30779 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756412339.824818   30779 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756412339.824822   30779 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
          ]
        }
      ],
      "source": [
        "launch_website()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys57uvv9Kyvv"
      },
      "source": [
        "### 2.3.1. Coding Exercise: Adding Button Logic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWELTOc0u0Vt"
      },
      "source": [
        "Let's add some logic so we can get a prediction from our model when the button's pressed! A basic template for what the logic will look like is below.\n",
        "\n",
        "Technically, every time a user interacts with the site, your entire <font color=\"#0e86d4\"><b>`app.py`</b></font> file is run again. If they've clicked the button, `button` will be set to `True`, allowing the code in that `if` statement to run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fJvV33avVnr"
      },
      "source": [
        "```python\n",
        "if button: # (if button is pressed)\n",
        "    if text: # (if there exists text)\n",
        "        # Do something with that text\n",
        "    else:\n",
        "        st.error(\"Please enter a text to analyze.\") # Otherwise throw an error\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4ET0RDoFzyT"
      },
      "source": [
        "Copy the template below under <font color=\"green\">`### Button Logic`</font> in your <font color=\"#0e86d4\"><b>`app.py`</b></font>, and complete the code to use your predict function!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1K1rhMVvCbP"
      },
      "outputs": [],
      "source": [
        "if button:\n",
        "  if text:\n",
        "    ### Get Model's Prediction\n",
        "\n",
        "    # YOUR CODE HERE: Replace the None with the model's prediction!\n",
        "    probabilities = predict(text)\n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Pair the labels with the probabilities in a dictionary\n",
        "    labels = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "    # Print out the results on the Streamlit site\n",
        "    st.write(\"Sentiment Probabilities:\")\n",
        "    for label, prob in zip(labels, probabilities):\n",
        "      st.write(f\"{label}: {prob:.4f}\")\n",
        "  else:\n",
        "    st.error(\"Please enter a text to analyze.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_iPdoL7xIa1"
      },
      "source": [
        "Now, rerun your <font color=\"#0e86d4\"><b>`app.py`</b></font> file cell and test out your new website. What happens when you click the button now?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "gjV2_oD3y1DG",
        "outputId": "c0690aa4-e96e-4491-d132-accc86a6ad9a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'launch_website' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4102299476.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlaunch_website\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'launch_website' is not defined"
          ]
        }
      ],
      "source": [
        "launch_website()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fetgQOoixpFI"
      },
      "source": [
        "## (Optional) **2.4. Visualizations**\n",
        "\n",
        ">Your website should be complete, but feel free to explore this section to add an example visualization!  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PuharFexriX"
      },
      "source": [
        "Our website will look much better with some visualizations of our data and our model's performance. We can create these using <font color=\"#0e86d4\"><b>Plotly</b></font> - a library similar to Matplotlib and Seaborn that works very well with Streamlit! Let's import it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I11SGMZAwZlS"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-3XNTIuWltL"
      },
      "source": [
        "First, we need to set labels to our sentiments. Recall that:\n",
        "\n",
        "* <font color=#FF474C>\n",
        "Negative is 0\n",
        "</font>\n",
        "* <font color=#636363>\n",
        "Neutral is 1\n",
        "</font>\n",
        "* <font color=#00ab41>\n",
        "Positive is 2\n",
        "</font>\n",
        "\n",
        "Run the code cell below to add a column to the dataset with these labels rather than the hard-to-understand numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4gy-nK-xygK"
      },
      "outputs": [],
      "source": [
        "# Define label dictionary\n",
        "sentiment_label_map = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
        "\n",
        "# Load in data and add more descriptive column\n",
        "df_train = get_finance_train()\n",
        "df_train['Sentiment'] = df_train['Label'].map(sentiment_label_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q78FEXKCyfe5"
      },
      "source": [
        "### **Pie Chart**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR1zQlkhW0zl"
      },
      "source": [
        "One of the easiest visualizations we can do is a pie chart. Let's create a pie chart to visualize the distribution of our training data.\n",
        "\n",
        "To do this, we can use the method `.value_counts()` on the `'Sentiment'` column of the dataset, as you can see below. Run the cell to see the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0O3Ecs45vg2"
      },
      "outputs": [],
      "source": [
        "# Count occurences of each sentiment\n",
        "sentiment_counts = df_train['Sentiment'].value_counts()\n",
        "sentiment_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V80c_AgNIDT"
      },
      "source": [
        "We'll also of course need some colors for the pie chart too! Below we've chosen a few colors for you, but you're more than welcome to change these values. We suggest using [Google's color picker](https://g.co/kgs/HwqhmCd) to explore different colors! You can find the code under HEX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Xze0lqoNIpO"
      },
      "outputs": [],
      "source": [
        "# Labels/colors - try changing these and looking up HEX values to customize the colors of your plot!\n",
        "color_map = {'Negative' : '#FF0000',\n",
        "             'Neutral'  : '#999999',\n",
        "             'Positive' : '#00FF00'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMoIeo6etV5y"
      },
      "source": [
        "### 2.4.1. Coding Exercise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNrcWseGZVDx"
      },
      "source": [
        "Now, we can use these to pass parameters into our <font color=\"#0e86d4\"><b>`px.pie()`</b></font> function to build our plot.\n",
        "Fill in the <font color=\"#0e86d4\"><b>`None`</b></font> values with what we've found so far!\n",
        "\n",
        "Here's some more information on what each piece of the pie does. If you're curious, you can also take a look at the [documentation](https://plotly.com/python-api-reference/generated/plotly.express.pie) for more info.\n",
        "\n",
        "* <font color=\"#0e86d4\"><b>`names`</b></font>: the labels of the pie chart slices\n",
        "* <font color=\"#0e86d4\"><b>`values`</b></font>: the number values we want to base the pie chart off of, in the same order as <font color=\"#0e86d4\"><b>`names`</b></font>\n",
        "* <font color=\"#0e86d4\"><b>`title`</b></font>: the title of our chart\n",
        "* <font color=\"#0e86d4\"><b>`color`</b></font>: this is what the chart uses to know what the labels are that we're assigning colors to\n",
        "* <font color=\"#0e86d4\"><b>`color_discrete_map`</b></font> = the mapping of labels to colors we are using for our pie chart\n",
        "\n",
        "*Hint:*\n",
        "<details><summary>click to reveal!</summary>\n",
        "\n",
        "\n",
        ">Remember when we got the value counts of the sentiments in the previous section? We can use that info for our pie chart! Here's how you'd retrieve that information; make sure you place these in the correct field below\n",
        "* Use <font color=\"#0e86d4\"><b>`sentiment_counts.index`</b></font> to get the index values from the first column (the one in bold)\n",
        "* Use <font color=\"#0e86d4\"><b>`sentiment_counts.values`</b></font> to get the values in the second column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95Smjn7U2AsL"
      },
      "outputs": [],
      "source": [
        "fig = px.pie(\n",
        "    names=None,\n",
        "    values=None,\n",
        "    title=None,\n",
        "    color=None,\n",
        "    color_discrete_map=None\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCzIwvlC5m1G"
      },
      "source": [
        "### 2.4.2. Coding Exercise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng9EQNT85sLT"
      },
      "source": [
        "Try adding a pie chart to your <font color=\"#0e86d4\"><b>`app.py`</b></font> file now! Instead of displaying the information about the dataset, let's generate a pie chart that visualizes the probabilities that the model predicts so that it's easier to compare those visually.\n",
        "\n",
        "The code should be very similar to what we've written above, except using the labels and probabilities we've coded in the file! We'll also need to replace `fig.show()` with `st.plotly_chart(fig)` so it displays on our Streamlit site rather than here in this coding notebook.\n",
        "\n",
        "Once you have that code in your file, rerun it and run the cell below to test it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO_IZffszLp1",
        "outputId": "2f5f9861-6f75-416f-980b-7bd29680cd5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Click this link to try your web app:\n",
            "https://0dcee31304a7.ngrok-free.app\n",
            "2025-08-27 05:11:47.169524: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756271507.201252    2034 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756271507.210381    2034 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756271507.233889    2034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756271507.233942    2034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756271507.233949    2034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756271507.233954    2034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
          ]
        }
      ],
      "source": [
        "launch_website()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mACzv6SLdqjm"
      },
      "source": [
        "---\n",
        "---\n",
        "# üéÅ **Wrapping Up**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51SPcR1Bd95Q"
      },
      "source": [
        "You should have a nice web app to show off your project now! Feel free to continue experimenting with more visualizations from your project or more bells and whistles on the website. The [Streamlit cheat sheet](https://docs.streamlit.io/develop/quick-reference/cheat-sheet) is a great resource to get you started!\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "n7Rz7HxjD2KA",
        "fetgQOoixpFI"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}